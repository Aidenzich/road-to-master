# Time Series 
## Papers
| Title | Venue | Year | Code | Review | 
|-|-|-|-|-|
| [Non-stationary Transformers: Exploring the Stationarity in Time Series Forecasting](./https://arxiv.org/pdf/2205.14415.pdf) | NIPS | '22 | [âœ“](https://github.com/thuml/Nonstationary_Transformers) | [ðŸ”§](./Non-stationary-Transformers/) |
| [PSA-GAN: Progressive self attention GANs for synthetic time series](https://www.amazon.science/publications/psa-gan-progressive-self-attention-gans-for-synthetic-time-series) | ICLR | ['22](https://aaai.org/Conferences/AAAI-21/aaai21call/#) | [âœ“](https://github.com/awslabs/gluon-ts/tree/dev/src) | [ðŸ”§](./psa-gan/) |
| [Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting](https://arxiv.org/pdf/2106.13008.pdf) | NIPS | '21 | [âœ“](https://github.com/thuml/Autoformer) | [âœ“](./Autoformer/) |
| [Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436) | AAAI | ['21](https://aaai.org/Conferences/AAAI-21/aaai21call/#) | [âœ“](https://github.com/zhouhaoyi/Informer2020) | [ðŸ”§](./informer/)|
