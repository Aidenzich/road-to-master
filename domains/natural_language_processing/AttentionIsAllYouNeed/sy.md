Synthesizer 和 FNet 這些論文雖然在學術上很精彩（證明了 QKV 不是不可或缺），但在**「通用大模型（General LLM）」**的戰場上，它們確實輸了。現在所有的主流最強模型（GPT-4, Claude 3, LLaMA 3）全部都死守 QKV 架構。

原因並不是因為慣性，而是因為 Synthesizer 這類「去 QK 化」的方法，在**三個關鍵能力**上存在致命的天花板。這三個能力恰恰是我們對現代 LLM 最看重的：

### 1. In-Context Learning (上下文學習能力) —— 這是致命傷

這是 GPT 系列能成功的核心：**「不更新參數，也能學會新任務」。**

* **QKV 的機制：**
    它是**動態的 (Dynamic)**。當你在 Prompt 裡給出幾個範例（Few-shot）時，QKV 機制會讓模型在推論當下，直接去「抄」前面範例的模式。
    > 比如你輸入：「蘋果: 紅色, 香蕉: 黃色, 草莓: 」，模型會透過 $QK^T$ 強力關注前面的格式，然後輸出「紅色」。這是一種**即時的 (Run-time) 關聯建立**。

* **Synthesizer/FNet 的機制：**
    它是**靜態的**或**全域的 (Global)**。它的 Attention Map 更多是依賴**訓練時背下來的權重**。
    它傾向於學習「一般性的語法規則」（例如：名詞後面通常接動詞），但它很難在**推論當下**去精確捕捉「這個特定的 Prompt 裡，A 和 B 的特殊關係」。

**結論：** 拿掉 QKV，模型會變得很像 BERT（擅長理解），但會失去 GPT 的靈魂（擅長模仿與推論）。

### 2. 處理「長尾」與「歧義」的能力 (Expressivity)

語言充滿了歧義，而解決歧義需要極度依賴**「當下的對手是誰」**，這正是 $QK^T$ (Content-based interaction) 的強項。

舉個例子：**"Bank"** (銀行/河岸)。

* **QKV (Dot-product):**
    如果句子裡有 "Money"，$Q_{\text{Bank}}$ 和 $K_{\text{Money}}$ 的點積會很高 $\rightarrow$ 啟動「金融」意義。
    如果句子裡有 "River"，$Q_{\text{Bank}}$ 和 $K_{\text{River}}$ 的點積會很高 $\rightarrow$ 啟動「地理」意義。
    **它是「看菜吃飯」的。**

* **Synthesizer (Fixed Weights):**
    它傾向於學習一個平均的權重。它可能學到 "Bank" 這個位置通常需要關注周圍 5 個字。但它無法像 QKV 那樣，根據**內容本身**做出那麼劇烈的權重切換。

**結論：** Synthesizer 在標準數據集上表現好（95% 性能），是因為大部分語言是規律的。但在處理那剩下的 5% 複雜歧義或高難度推理時，QKV 的「精確點對點比對」是無可替代的。而在 LLM 競爭中，那 5% 的智商差距就是勝負關鍵。

### 3. 長度外推性 (Length Extrapolation)

這是一個工程上的實務問題。

* **QKV:**
    因為它是基於內容比對，理論上只要搭配好的位置編碼（如 RoPE），我在訓練時只看過 4k 長度，推論時硬推到 8k，QKV 還是能運作（因為它是在比相似度）。

* **Synthesizer / MLP-Mixer:**
    它們通常涉及**固定大小的矩陣參數**。如果你訓練時是 512 個 token，它的矩陣大小就是 $512 \times 512$。
    如果推論時來了 1024 個 token，這種架構往往需要用插值（Interpolation）或其他很醜的工程手段來解決，效果通常會崩跌。

---

### 總結：為什麼 QKV 還是王者？

這就像是 **「計程車 (QKV)」** vs **「公車 (Synthesizer)」**。

* **公車 (Synthesizer):**
    路線固定（權重固定），效率高，大部分時候能把你送到目的地附近。
* **計程車 (QKV):**
    沒有固定路線，你想去哪就載你直接去哪（根據 Input 動態決定路徑）。

在小模型或簡單任務上，公車就夠了（所以 Google 的論文說它有效）。
但在追求 **AGI（通用人工智慧）** 的路上，我們需要的是能夠處理**任何未知情況、任何奇怪 Prompt** 的能力，這種**極致的動態性（Dynamic Routing）**，目前只有 $QK^T$ 的矩陣乘法能完美提供。

這也是為什麼雖然 $O(N^2)$ 的計算成本很高，大家還是咬牙付這個錢，因為**為了那個「In-Context Learning」的靈性，這個代價是值得的。** 不過，雖然 Synthesizer 輸了，但**「挑戰 Transformer 效率」**這條路並沒有死，現在接棒的是 **Mamba (SSM)** 和 **Linear Attention**（如 RWKV）。